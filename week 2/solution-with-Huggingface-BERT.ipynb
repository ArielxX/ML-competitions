{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T08:02:19.374717Z","iopub.execute_input":"2023-08-10T08:02:19.375447Z","iopub.status.idle":"2023-08-10T08:02:19.41239Z","shell.execute_reply.started":"2023-08-10T08:02:19.375407Z","shell.execute_reply":"2023-08-10T08:02:19.41141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"code","source":"COMMON_PATH = \"/kaggle/input/commonlit-evaluate-student-summaries/\"","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.414219Z","iopub.execute_input":"2023-08-10T08:02:19.414767Z","iopub.status.idle":"2023-08-10T08:02:19.4196Z","shell.execute_reply.started":"2023-08-10T08:02:19.414718Z","shell.execute_reply":"2023-08-10T08:02:19.418344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_df = pd.read_csv(COMMON_PATH + \"summaries_train.csv\")\nsummary_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.421279Z","iopub.execute_input":"2023-08-10T08:02:19.421993Z","iopub.status.idle":"2023-08-10T08:02:19.493727Z","shell.execute_reply.started":"2023-08-10T08:02:19.421958Z","shell.execute_reply":"2023-08-10T08:02:19.492655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_df = pd.read_csv(COMMON_PATH + \"prompts_train.csv\")\nprompt_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.496537Z","iopub.execute_input":"2023-08-10T08:02:19.496899Z","iopub.status.idle":"2023-08-10T08:02:19.511478Z","shell.execute_reply.started":"2023-08-10T08:02:19.496867Z","shell.execute_reply":"2023-08-10T08:02:19.510306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = summary_df.merge(prompt_df, on=\"prompt_id\", how='inner')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.513115Z","iopub.execute_input":"2023-08-10T08:02:19.513454Z","iopub.status.idle":"2023-08-10T08:02:19.533762Z","shell.execute_reply.started":"2023-08-10T08:02:19.513423Z","shell.execute_reply":"2023-08-10T08:02:19.532851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['student_id', 'prompt_id'], axis=1, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.535304Z","iopub.execute_input":"2023-08-10T08:02:19.535675Z","iopub.status.idle":"2023-08-10T08:02:19.556003Z","shell.execute_reply.started":"2023-08-10T08:02:19.535641Z","shell.execute_reply":"2023-08-10T08:02:19.554963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NLP stuff","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:19.559028Z","iopub.execute_input":"2023-08-10T08:02:19.559333Z","iopub.status.idle":"2023-08-10T08:02:20.405355Z","shell.execute_reply.started":"2023-08-10T08:02:19.559296Z","shell.execute_reply":"2023-08-10T08:02:20.404366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path_or_name = '../input/huggingface-bert/bert-base-cased'\nbert_model = AutoModel.from_pretrained(model_path_or_name)\ntokenizer = AutoTokenizer.from_pretrained(model_path_or_name)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:20.406639Z","iopub.execute_input":"2023-08-10T08:02:20.407766Z","iopub.status.idle":"2023-08-10T08:02:26.749853Z","shell.execute_reply.started":"2023-08-10T08:02:20.407728Z","shell.execute_reply":"2023-08-10T08:02:26.748804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.add_special_tokens({'pad_token': '[PAD]'})","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:26.754042Z","iopub.execute_input":"2023-08-10T08:02:26.754353Z","iopub.status.idle":"2023-08-10T08:02:26.760954Z","shell.execute_reply.started":"2023-08-10T08:02:26.754327Z","shell.execute_reply":"2023-08-10T08:02:26.759911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.tokenize(\"Hello, is it me you're looking for?\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:26.762311Z","iopub.execute_input":"2023-08-10T08:02:26.76299Z","iopub.status.idle":"2023-08-10T08:02:26.774334Z","shell.execute_reply.started":"2023-08-10T08:02:26.762957Z","shell.execute_reply":"2023-08-10T08:02:26.773353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:26.775997Z","iopub.execute_input":"2023-08-10T08:02:26.776364Z","iopub.status.idle":"2023-08-10T08:02:26.782338Z","shell.execute_reply.started":"2023-08-10T08:02:26.776329Z","shell.execute_reply":"2023-08-10T08:02:26.781073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n        self.data_text_format = \"\"\"\n            Task: Question-Conditioned Text Summarization\n\n            Question: \"{}\"\n\n            Given the following text, provide a concise summary that answers the question:\n\n            Text: \"{}\"\n\n            Summary: {}\n\n            ---\n            \"\"\"\n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        text = self.df.loc[idx, 'text']\n        question = self.df.loc[idx, 'prompt_question'][10:]\n        fulltext = self.df.loc[idx, 'prompt_title'] + '\\n' + self.df.loc[idx, 'prompt_text']\n        \n        try:\n            target_1 = self.df.loc[idx, 'content']\n            target_2 = self.df.loc[idx, 'wording']\n\n            target = [float(target_1), float(target_2)]\n        except:\n            target = [0,0]\n        \n        content = self.data_text_format.format(question, fulltext, text)\n        \n        inputs = self.tokenizer.encode_plus(content, truncation = True, padding=True, max_length=self.max_length, return_tensors='pt')\n        \n        input_ids = inputs['input_ids'].squeeze()\n        \n        return {\n            'input_ids': input_ids,\n            'targets': torch.tensor(target, dtype=torch.float)\n        }\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:26.783848Z","iopub.execute_input":"2023-08-10T08:02:26.784424Z","iopub.status.idle":"2023-08-10T08:02:26.797426Z","shell.execute_reply.started":"2023-08-10T08:02:26.78439Z","shell.execute_reply":"2023-08-10T08:02:26.796663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's try to see the distribution of the number of tokens","metadata":{}},{"cell_type":"code","source":"dataset = RawDataset(df, tokenizer, None)\nlens = [dataset[i]['input_ids'].shape[0] for i in range(len(dataset))]\n\nimport matplotlib.pyplot as plt \nplt.hist(lens, density=True)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-10T08:02:26.798825Z","iopub.execute_input":"2023-08-10T08:02:26.799475Z","iopub.status.idle":"2023-08-10T08:02:56.339592Z","shell.execute_reply.started":"2023-08-10T08:02:26.799442Z","shell.execute_reply":"2023-08-10T08:02:56.338627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset), len(df)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:56.340921Z","iopub.execute_input":"2023-08-10T08:02:56.341776Z","iopub.status.idle":"2023-08-10T08:02:56.348621Z","shell.execute_reply.started":"2023-08-10T08:02:56.34174Z","shell.execute_reply":"2023-08-10T08:02:56.347645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:56.350022Z","iopub.execute_input":"2023-08-10T08:02:56.351205Z","iopub.status.idle":"2023-08-10T08:02:56.358734Z","shell.execute_reply.started":"2023-08-10T08:02:56.351168Z","shell.execute_reply":"2023-08-10T08:02:56.357669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = RawDataset(df, tokenizer, MAX_LEN)\ndataset[2]['input_ids'].shape","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:56.359965Z","iopub.execute_input":"2023-08-10T08:02:56.360919Z","iopub.status.idle":"2023-08-10T08:02:56.374656Z","shell.execute_reply.started":"2023-08-10T08:02:56.360886Z","shell.execute_reply":"2023-08-10T08:02:56.37362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lens = [dataset[i]['input_ids'].shape[0] for i in range(len(dataset))]\n\nimport matplotlib.pyplot as plt \nplt.hist(lens, density=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:02:56.376409Z","iopub.execute_input":"2023-08-10T08:02:56.376763Z","iopub.status.idle":"2023-08-10T08:03:24.165682Z","shell.execute_reply.started":"2023-08-10T08:02:56.376731Z","shell.execute_reply":"2023-08-10T08:03:24.164649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Learning Model","metadata":{}},{"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda:0\")\n    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n        return torch.device(\"mps\")\n    else:\n        return torch.device(\"cpu\")\n\ndevice=get_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:24.16696Z","iopub.execute_input":"2023-08-10T08:03:24.167355Z","iopub.status.idle":"2023-08-10T08:03:24.202934Z","shell.execute_reply.started":"2023-08-10T08:03:24.167321Z","shell.execute_reply":"2023-08-10T08:03:24.201931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:24.204401Z","iopub.execute_input":"2023-08-10T08:03:24.205041Z","iopub.status.idle":"2023-08-10T08:03:24.226471Z","shell.execute_reply.started":"2023-08-10T08:03:24.205006Z","shell.execute_reply":"2023-08-10T08:03:24.225674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Freezing layers from BERT","metadata":{}},{"cell_type":"code","source":"for param in bert_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:24.227786Z","iopub.execute_input":"2023-08-10T08:03:24.228461Z","iopub.status.idle":"2023-08-10T08:03:24.23614Z","shell.execute_reply.started":"2023-08-10T08:03:24.228428Z","shell.execute_reply":"2023-08-10T08:03:24.234996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn \n\nclass RegressionModel(nn.Module):\n    def __init__(self, model):\n        super(RegressionModel, self).__init__()\n        self.model = model\n        self.linear = nn.Linear(768, 2)\n        \n    def forward(self, x):\n        y = self.model(x).last_hidden_state\n        y = y[:,-1,:]\n        y = self.linear(y)\n        return y\n\nmodel = RegressionModel(bert_model).to(device=device)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:24.237571Z","iopub.execute_input":"2023-08-10T08:03:24.237936Z","iopub.status.idle":"2023-08-10T08:03:26.680681Z","shell.execute_reply.started":"2023-08-10T08:03:24.237901Z","shell.execute_reply":"2023-08-10T08:03:26.679642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training / Transfer Learning","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:26.682324Z","iopub.execute_input":"2023-08-10T08:03:26.682727Z","iopub.status.idle":"2023-08-10T08:03:26.687558Z","shell.execute_reply.started":"2023-08-10T08:03:26.682676Z","shell.execute_reply":"2023-08-10T08:03:26.686474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3\n\n# Create dataset and data loader\ndataset = RawDataset(df, tokenizer, max_length=MAX_LEN)\ndata_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n\n# Fine-tune the model (use an appropriate optimizer and loss function)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nloss_fn = torch.nn.MSELoss()\n\nmodel.train()\n\nfor epoch in range(num_epochs):\n    iterr = tqdm(data_loader, f\"epoch {epoch+1}/{num_epochs}\")\n    for batch in iterr:\n        inputs = batch['input_ids'].to(device=device)\n        targets = batch['targets'].to(device=device)\n        \n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:03:26.694022Z","iopub.execute_input":"2023-08-10T08:03:26.69433Z","iopub.status.idle":"2023-08-10T08:10:31.513928Z","shell.execute_reply.started":"2023-08-10T08:03:26.694306Z","shell.execute_reply":"2023-08-10T08:10:31.512883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:10:49.884814Z","iopub.execute_input":"2023-08-10T08:10:49.885257Z","iopub.status.idle":"2023-08-10T08:10:50.865687Z","shell.execute_reply.started":"2023-08-10T08:10:49.885225Z","shell.execute_reply":"2023-08-10T08:10:50.864329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"COMMON_PATH","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:10:54.71848Z","iopub.execute_input":"2023-08-10T08:10:54.719224Z","iopub.status.idle":"2023-08-10T08:10:54.725754Z","shell.execute_reply.started":"2023-08-10T08:10:54.719188Z","shell.execute_reply":"2023-08-10T08:10:54.724595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_test = pd.read_csv(COMMON_PATH + 'summaries_test.csv')\nprompt_test = pd.read_csv(COMMON_PATH + 'prompts_test.csv')\n\ndf_test = summary_test.merge(prompt_test, on=\"prompt_id\", how='inner')\ndf.head()\n\ndataset = RawDataset(df_test, tokenizer, max_length=MAX_LEN)\ndata_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:10:56.405015Z","iopub.execute_input":"2023-08-10T08:10:56.405396Z","iopub.status.idle":"2023-08-10T08:10:56.737497Z","shell.execute_reply.started":"2023-08-10T08:10:56.405368Z","shell.execute_reply":"2023-08-10T08:10:56.736407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:00.449062Z","iopub.execute_input":"2023-08-10T08:11:00.449915Z","iopub.status.idle":"2023-08-10T08:11:00.464281Z","shell.execute_reply.started":"2023-08-10T08:11:00.449866Z","shell.execute_reply":"2023-08-10T08:11:00.463352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:01.520345Z","iopub.execute_input":"2023-08-10T08:11:01.520733Z","iopub.status.idle":"2023-08-10T08:11:01.527808Z","shell.execute_reply.started":"2023-08-10T08:11:01.520684Z","shell.execute_reply":"2023-08-10T08:11:01.526655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nwith torch.no_grad():\n    iterr = tqdm(data_loader)\n    for batch in iterr:\n        inputs = batch['input_ids'].to(device=device)\n        \n        outputs = model(inputs)\n        print(outputs.shape)\n        predictions.append(outputs.cpu())\n        \npredictions","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:02.645299Z","iopub.execute_input":"2023-08-10T08:11:02.646067Z","iopub.status.idle":"2023-08-10T08:11:02.709832Z","shell.execute_reply.started":"2023-08-10T08:11:02.64602Z","shell.execute_reply":"2023-08-10T08:11:02.708862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:03.492164Z","iopub.execute_input":"2023-08-10T08:11:03.492547Z","iopub.status.idle":"2023-08-10T08:11:03.499226Z","shell.execute_reply.started":"2023-08-10T08:11:03.492517Z","shell.execute_reply":"2023-08-10T08:11:03.49806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[0].shape, predictions[1].shape","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:06.278806Z","iopub.execute_input":"2023-08-10T08:11:06.279746Z","iopub.status.idle":"2023-08-10T08:11:06.28652Z","shell.execute_reply.started":"2023-08-10T08:11:06.279684Z","shell.execute_reply":"2023-08-10T08:11:06.285513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concatenated_predictions = torch.cat(predictions, dim=0)\nconcatenated_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:08.050034Z","iopub.execute_input":"2023-08-10T08:11:08.051032Z","iopub.status.idle":"2023-08-10T08:11:08.059341Z","shell.execute_reply.started":"2023-08-10T08:11:08.050987Z","shell.execute_reply":"2023-08-10T08:11:08.058037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = df_test\nsubmission[['content', 'wording']] = concatenated_predictions.numpy()\nsubmission = submission.drop(['prompt_id', 'text', 'prompt_question', 'prompt_title', 'prompt_text'], axis=1)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:10.637756Z","iopub.execute_input":"2023-08-10T08:11:10.638464Z","iopub.status.idle":"2023-08-10T08:11:10.653237Z","shell.execute_reply.started":"2023-08-10T08:11:10.63843Z","shell.execute_reply":"2023-08-10T08:11:10.651989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv' ,index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T08:11:23.281877Z","iopub.execute_input":"2023-08-10T08:11:23.282255Z","iopub.status.idle":"2023-08-10T08:11:23.290008Z","shell.execute_reply.started":"2023-08-10T08:11:23.282226Z","shell.execute_reply":"2023-08-10T08:11:23.288754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}